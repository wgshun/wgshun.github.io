<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[机器学习中的数学]]></title>
    <url>%2F2018%2F07%2Fmath-in-ml%2F</url>
    <content type="text"><![CDATA[偏导数多变量函数指的是具有多个参数的函数，例如： f(x,y) = e^{2y}sin(x)$f$ 相对于 $x$ 的偏导数表示如下： \partial f \over \partial x是 $f (x)$ 的导数。要计算以下值： \partial f \over \partial x您必须使 $y$ 保持固定不变（因此 $f$ 现在是只有一个变量 $x$ 的函数），然后取 $f$ 相对于 $x$ 的常规导数。例如，当 $y$ 固定为 1 时，前面的函数变为： f(x) = e^2sin(x)这只是一个变量 $x$ 的函数，其导数为： e^2cos(x) 一般来说，假设 $y$ 保持不变，$f$ 对 $x$ 的偏导数的计算公式如下： \frac{\partial f}{\partial x}(x,y) = e^{2y}cos(x)同样，如果我们使 $x$ 保持不变，$f$ 对 $y$ 的偏导数为： \frac{\partial f}{\partial y}(x,y) = 2e^{2y}sin(x)直观而言，偏导数可以让您了解到，当您略微改动一个变量时，函数会发生多大的变化。在前面的示例中： \frac{\partial f}{\partial x} (0,1) = e^2 \approx 7.4因此，如果您将起点设为 (0,1)，使 $y$ 保持固定不变并将 $x$ 移动一点，$f$ 的变化量将是 $x$ 变化量的 7.4 倍左右。 在机器学习中，偏导数主要与函数的梯度一起使用。 梯度函数的梯度是偏导数相对于所有自变量的矢量，表示如下： \nabla f例如，如果： f(x,y) = e^{2y}sin(x)则： \nabla f(x,y) = (\frac{\partial f}{\partial x}(x,y), \frac{\partial f}{\partial y}(x,y)) = (e^{2y}cos(x), 2e^{2y}sin(x))请注意以下几点： $\nabla f$ 指向函数增长速度最快的方向。 ${-\nabla f}$ 指向函数下降速度最快的方向。 该矢量中的维度个数等于 $f$ 公式中的变量个数；换言之，该矢量位于该函数的域空间内。例如，在三维空间中查看下面的函数 $f(x,y)$ 时： f(x,y) = 4 + (x - 2)^2 + 2y^2$z = f(x,y)$ 就像一个山谷，最低点为 (2,0,4)：$f(x,y)$ 的梯度是一个二维矢量，可让您了解向哪个 $(x,y)$ 方向移动时高度下降得最快。也就是说，梯度矢量指向山谷。在机器学习中，梯度用于梯度下降法。我们的损失函数通常具有很多变量，而我们尝试通过跟随函数梯度的负方向来尽量降低损失函数。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>偏导数</tag>
        <tag>梯度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[降低损失]]></title>
    <url>%2F2018%2F07%2Freducing-loss%2F</url>
    <content type="text"><![CDATA[迭代方法迭代学习可能会让您想到“Hot and Cold”这种寻找隐藏物品（如顶针）的儿童游戏。在我们的游戏中，“隐藏的物品”就是最佳模型。刚开始，您会胡乱猜测（“ $w_1$ 的值为 0。”），等待系统告诉您损失是多少。然后，您再尝试另一种猜测（“ $w_1$ 的值为 0.5。”），看看损失是多少。哎呀，这次更接近目标了。实际上，如果您以正确方式玩这个游戏，通常会越来越接近目标。这个游戏真正棘手的地方在于尽可能高效地找到最佳模型。 下图显示了机器学习算法用于训练模型的迭代试错过程： 我们将在整个机器学习速成课程中使用相同的迭代方法详细说明各种复杂情况，尤其是处于暴风雨中的蓝云区域。迭代策略在机器学习中的应用非常普遍，这主要是因为它们可以很好地扩展到大型数据集。 “模型”部分将一个或多个特征作为输入，然后返回一个预测 (y’) 作为输出。为了进行简化，不妨考虑一种采用一个特征并返回一个预测的模型： y' = b + w_1x_1我们应该为 $b$ 和 $w_1$ 设置哪些初始值？对于线性回归问题，事实证明初始值并不重要。我们可以随机选择值，不过我们还是选择采用以下这些无关紧要的值： $b$ = 0 $w_1$ = 0 假设第一个特征值是 10。将该特征值代入预测函数会得到以下结果：12y' = 0 + 0(10)y' = 0 图中的”计算损失”部分是模型将要使用的损失函数。假设我们使用平方损失函数。损失函数将采用两个输入值： y’：模型对特征 x 的预测 y：特征 x 对应的正确标签。 最后，我们来看图的“计算参数更新”部分。机器学习系统就是在此部分检查损失函数的值，并为 $b$ 和 $w_1$ 生成新值。现在，假设这个神秘的绿色框会产生新值，然后机器学习系统将根据所有标签重新评估所有特征，为损失函数生成一个新值，而该值又产生新的参数值。这种学习过程会持续迭代，直到该算法发现损失可能最低的模型参数。通常，您可以不断迭代，直到总体损失不再变化或至少变化极其缓慢为止。这时候，我们可以说该模型已收敛。 梯度下降法迭代方法图（图 1）包含一个标题为“计算参数更新”的华而不实的绿框。现在，我们将用更实质的方法代替这种华而不实的算法。 假设我们有时间和计算资源来计算 $w_1$ 的所有可能值的损失。对于我们一直在研究的回归问题，所产生的损失与 $w_1$ 的图形始终是凸形。换言之，图形始终是碗状图，如下所示： 凸形问题只有一个最低点；即只存在一个斜率正好为 0 的位置。这个最小值就是损失函数收敛之处。 通过计算整个数据集中 $w_1$ 每个可能值的损失函数来找到收敛点这种方法效率太低。我们来研究一种更好的机制，这种机制在机器学习领域非常热门，称为梯度下降法。 梯度下降法的第一个阶段是为 $w_1$ 选择一个起始值（起点）。起点并不重要；因此很多算法就直接将 $w_1$ 设为 0 或随机选择一个值。下图显示的是我们选择了一个稍大于 0 的起点： 然后，梯度下降法算法会计算损失曲线在起点处的梯度。简而言之，梯度是偏导数的矢量；它可以让您了解哪个方向距离目标“更近”或“更远”。请注意，损失相对于单个权重的梯度（如图 3 所示）就等于导数。 想要详细了解偏导数和梯度。点击链接 请注意，梯度是一个矢量，因此具有以下两个特征： 方向 大小 梯度始终指向损失函数中增长最为迅猛的方向。梯度下降法算法会沿着负梯度的方向走一步，以便尽快降低损失。 为了确定损失函数曲线上的下一个点，梯度下降法算法会将梯度大小的一部分与起点相加，如下图所示： 然后，梯度下降法会重复此过程，逐渐接近最低点。 随机梯度下降法在梯度下降法中，批量指的是用于在单次迭代中计算梯度的样本总数。到目前为止，我们一直假定批量是指整个数据集。就 Google 的规模而言，数据集通常包含数十亿甚至数千亿个样本。此外，Google 数据集通常包含海量特征。因此，一个批量可能相当巨大。如果是超大批量，则单次迭代就可能要花费很长时间进行计算。 包含随机抽样样本的大型数据集可能包含冗余数据。实际上，批量大小越大，出现冗余的可能性就越高。一些冗余可能有助于消除杂乱的梯度，但超大批量所具备的预测价值往往并不比大型批量高。 如果我们可以通过更少的计算量得出正确的平均梯度，会怎么样？通过从我们的数据集中随机选择样本，我们可以通过小得多的数据集估算（尽管过程非常杂乱）出较大的平均值。 随机梯度下降法 (SGD) 将这种想法运用到极致，它每次迭代只使用一个样本（批量大小为 1）。如果进行足够的迭代，SGD 也可以发挥作用，但过程会非常杂乱。“随机”这一术语表示构成各个批量的一个样本都是随机选择的。 小批量随机梯度下降法（小批量 SGD）是介于全批量迭代与 SGD 之间的折衷方案。小批量通常包含 10-1000 个随机选择的样本。小批量 SGD 可以减少 SGD 中的杂乱样本数量，但仍然比全批量更高效。 为了简化说明，我们只针对单个特征重点介绍了梯度下降法。请放心，梯度下降法也适用于包含多个特征的特征集。 学习速率正如之前所述，梯度矢量具有方向和大小。梯度下降法算法用梯度乘以一个称为学习速率（有时也称为步长）的标量，以确定下一个点的位置。例如，如果梯度大小为 2.5，学习速率为 0.01，则梯度下降法算法会选择距离前一个点 0.025 的位置作为下一个点。 超参数是编程人员在机器学习算法中用于调整的旋钮。大多数机器学习编程人员会花费相当多的时间来调整学习速率。如果您选择的学习速率过小，就会花费太长的学习时间： 相反，如果您指定的学习速率过大，下一个点将永远在 U 形曲线的底部随意弹跳，就好像量子力学实验出现了严重错误一样： 每个回归问题都存在一个金发姑娘1学习速率。“金发姑娘”值与损失函数的平坦程度相关。如果您知道损失函数的梯度较小，则可以放心地试着采用更大的学习速率，以补偿较小的梯度并获得更大的步长。 理想的学习速率: 一维空间中的理想学习速率是 $\frac{ 1 }{ f(x)’’ }$ （$f(x)$ 对 $x$ 的二阶导数的倒数）。 二维或多维空间中的理想学习速率是海森矩阵（由二阶偏导数组成的矩阵）的倒数。 广义凸函数的情况则更为复杂。 检查您的理解情况：批量大小查看以下选项。 基于大型数据集执行梯度下降法时，以下哪个批量大小可能比较高效？ 小批量或甚至包含一个样本的批量 (SGD)。√ 全批量。× 注解： 令人惊讶的是，在小批量或甚至包含一个样本的批量上执行梯度下降法通常比全批量更高效。毕竟，计算一个样本的梯度要比计算数百万个样本的梯度成本低的多。为确保获得良好的代表性样本，该算法在每次迭代时都会抽取另一个随机小批量数据（或包含一个样本的批量数据）。 对全批量计算梯度这一做法的效率并不高。也就是说，与非常大的全批量相比，对较小的批量计算梯度通常高效得多（并且准确度无异）。 1. 童话《金发姑娘和三只熊》：迷路了的金发姑娘未经允许就进入了熊的房子，她尝了三只碗里的粥，试了三把椅子，又在三张床上躺了躺，最后决定小碗里的粥最可口，小椅子坐着最舒服，小床上躺着最惬意，因为那是最适合她的，不大不小刚刚好。金发姑娘选择事物的原则就叫Goldilocks principle（金发姑娘原则）。 &#8617;]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>降低损失</tag>
        <tag>梯度下降</tag>
        <tag>优化学习速率</tag>
        <tag>随机梯度下降</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入了解机器学习]]></title>
    <url>%2F2018%2F07%2Fdescending-into-ml%2F</url>
    <content type="text"><![CDATA[人们早就知晓，相比凉爽的天气，蟋蟀在较为炎热的天气里鸣叫更为频繁。数十年来，专业和业余昆虫学者已将每分钟的鸣叫声和温度方面的数据编入目录。Ruth 将她喜爱的蟋蟀数据库作为生日礼物送给您，并邀请您自己利用该数据库训练一个模型，从而预测鸣叫声与温度的关系。 首先建议您将数据绘制成图表，了解下数据的分布情况：毫无疑问，此曲线图表明温度随着鸣叫声次数的增加而上升。鸣叫声与温度之间的关系是线性关系吗？是的，您可以绘制一条直线来近似地表示这种关系，如下所示：事实上，虽然该直线并未精确无误地经过每个点，但针对我们拥有的数据，清楚地显示了鸣叫声与温度之间的关系。只需运用一点代数知识，您就可以将这种关系写下来，如下所示： y = mx + b其中： $y$ 指的是温度（以摄氏度表示），即我们试图预测的值。 $m$ 指的是直线的斜率。 $x$ 指的是每分钟的鸣叫声次数，即输入特征的值。 $b$ 指的是 y 轴截距。 按照机器学习的惯例，您需要写一个存在细微差别的模型方程式： y' = b + w_1x_1其中： $y’$ 指的是预测标签（理想输出值）。 $b$ 指的是偏差（y 轴截距）。而在一些机器学习文档中，它称为 $w_0$ 。 $w_1$ 指的是特征 1 的权重。权重与上文中用 $m$ 表示的“斜率”的概念相同。 $x_1$ 指的是特征（已知输入项）。 要根据新的每分钟的鸣叫声值 $x_1$ 推断（预测）温度 $y′$，只需将 $x_1$ 值代入此模型即可。下标（例如 $w_1$ 和 $x_1$）预示着可以用多个特征来表示更复杂的模型。例如，具有三个特征的模型可以采用以下方程式： y' = b + w_1x_1 + w_2x_2 + w_3x_3简单来说，训练模型表示通过有标签样本来学习（确定）所有权重和偏差的理想值。在监督式学习中，机器学习算法通过以下方式构建模型：检查多个样本并尝试找出可最大限度地减少损失的模型；这一过程称为经验风险最小化。 损失是对糟糕预测的惩罚。也就是说，损失是一个数值，表示对于单个样本而言模型预测的准确程度。如果模型的预测完全准确，则损失为零，否则损失会较大。训练模型的目标是从所有样本中找到一组平均损失“较小”的权重和偏差。例如，图 3 左侧显示的是损失较大的模型，右侧显示的是损失较小的模型。关于此图，请注意以下几点： 请注意，左侧曲线图中的红色箭头比右侧曲线图中的对应红色箭头长得多。显然，相较于左侧曲线图中的蓝线，右侧曲线图中的蓝线代表的是预测效果更好的模型。 您可能想知道自己能否创建一个数学函数（损失函数），以有意义的方式汇总各个损失。 平方损失：一种常见的损失函数接下来我们要看的线性回归模型使用的是一种称为平方损失（又称为 L2 损失）的损失函数。单个样本的平方损失如下：123= the square of the difference between the label and the prediction= (observation - prediction(x))²= (y - y')² 均方误差 (MSE) 指的是每个样本的平均平方损失。要计算 MSE，请求出各个样本的所有平方损失之和，然后除以样本数量： MSE = \frac{1}{N} \sum_{(x,y)\in D} (y - prediction(x))^2其中： $(x, y)$ 指的是样本，其中 $x$ 指的是模型进行预测时使用的特征集（例如，温度、年龄和交配成功率）。 $y$ 指的是样本的标签（例如，每分钟的鸣叫次数）。 $prediction(x)$ 指的是权重和偏差与特征集 $x$ 结合的函数。 $D$ 指的是包含多个有标签样本（即 $(x,y)$）的数据集。 $N$ 指的是 $D$ 中的样本数量。 虽然 MSE 常用于机器学习，但它既不是唯一实用的损失函数，也不是适用于所有情形的最佳损失函数。 检测理解情况均方误差请看以下两个曲线图： 查看以下选项，对于以上曲线图中显示的两个数据集，哪个数据集的均方误差 (MSE) 较高？ 左侧的数据集 × 右侧的数据集 √ 注解： 线上的 6 个样本产生的总损失为 0。不在线上的 4 个样本离线并不远，因此即使对偏移求平方值，产生的值仍然很小：MSE = \frac{0^2 + 1^2 + 0^2 + 1^2 + 0^2 + 1^2 + 0^2 + 1^2 + 0^2 + 0^2} {10} = 0.4 线上的 8 个样本产生的总损失为 0。不过，尽管只有两个点在线外，但这两个点的离线距离依然是左图中离群点的 2 倍。平方损失进一步加大差异，因此两个点的偏移量产生的损失是一个点的 4 倍。MSE = \frac{0^2 + 0^2 + 0^2 + 2^2 + 0^2 + 0^2 + 0^2 + 2^2 + 0^2 + 0^2} {10} = 0.8]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>线性回归</tag>
        <tag>训练模型</tag>
        <tag>损失函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo 博客绑定个人域名]]></title>
    <url>%2F2018%2F07%2Fcustom-domain%2F</url>
    <content type="text"><![CDATA[前段时间用 hexo 搭建的 gitpage 个人博客，服务器用的是 github 的，然后域名默认也是 github 下的二级域名：username.github.io, 现在为了提升格调准备将自己的博客指向一个新的域名。下面记录下过程。 购买域名国内的域名服务商有新网，腾讯云，还有阿里云的万网等。下面以阿里云的万网为例： 在万网购买了自己心仪的域名后，进入阿里云的管理控制台-域名与网站-域名就可以看到购买的域名此时的域名状态是未实名认证的，然后就是实名认证（一般需要2小时左右）。 域名解析首先获取自己 github 的二级域名的 IP地址，windows 下直接在 cmd 里 Ping 一下自己的博客就会得到 IP 地址：下面通过 DNS域名解析将购买的域名指向 github 的二级域名：username.github.io，进入阿里云的管理控制台-域名与网站-云解析 DNS，进入域名的解析设置，点击新手指导，将得到的 IP 地址填到记录值一栏，点击确定就 OK 了。填完以后的解析列表会出现：记录值就是自己 github 的二级域名的 IP地址。 设置CNAME在 hexo 项目下，source 文件夹下面创建 CNAME 文件（没有后缀名的），在里面写上购买的域名。比如： 在 github 上面，打开 username.github.io 项目的（Settings）设置，然后在 GitHub Pages的 Custom domain设置里填上购买的域名。比如： 好了，新域名配置完成，可以访问了。]]></content>
      <categories>
        <category>博客技术</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>绑定域名</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo 的 Next 主题中渲染 MathJax 数学公式]]></title>
    <url>%2F2018%2F07%2Fmathjax-in-hexo%2F</url>
    <content type="text"><![CDATA[在用markdown写技术文档时，免不了会碰到数学公式。常用的Markdown编辑器都会集成Mathjax，用来渲染文档中的类Latex格式书写的数学公式。基于Hexo搭建的个人博客，默认情况下渲染数学公式却会出现各种各样的问题。 这个问题搞了好久才找到解决方案，感谢@小毛驴 原因Hexo 默认使用 ”hexo-renderer-marked” 引擎渲染网页，该引擎会把一些特殊的 markdown 符号转换为相应的 html 标签，比如在 markdown 语法中，下划线_代表斜体，会被渲染引擎处理为&lt;em&gt;标签。 因为类 Latex 格式书写的数学公式下划线_表示下标，有特殊的含义，如果被强制转换为&lt;em&gt;标签，那么 MathJax 引擎在渲染数学公式的时候就会出错。 类似的语义冲突的符号还包括*, {, }, \\等。 解决方法更换 Hexo 的 markdown 渲染引擎，hexo-renderer-kramed 引擎是在默认的渲染引擎 hexo-renderer-marked 的基础上修改了一些 bug ，两者比较接近，也比较轻量级。12npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save 执行上面的命令即可，先卸载原来的渲染引擎，再安装新的。然后，跟换引擎后行间公式可以正确渲染了，但是这样还没有完全解决问题，行内公式的渲染还是有问题，因为 hexo-renderer-kramed 引擎也有语义冲突的问题。接下来到博客根目录下，找到node_modules\kramed\lib\rules\inline.js，把第11行的 escape 变量的值做相应的修改：12//escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,escape: /^\\([`*\[\]()#$+\-.!_&gt;])/, 这一步是在原基础上取消了对\\,\{,\}的转义(escape)。同时把第20行的em变量也要做相应的修改。12//em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, 重新启动hexo（先clean再generate）,问题完美解决。哦，如果不幸还没解决的话，看看是不是还需要在使用的主题中配置mathjax开关。 在 Next 主题中开启 MathJax 开关如何使用了主题了，别忘了在主题（Theme）中开启 MathJax 开关，下面以 next 主题为例，介绍下如何打开 MathJax 开关。 进入到主题目录，找到 _config.yml 配置问题，把 math 默认的 false 修改为true，具体如下： 1234567891011# Math Equations Render Supportmath: enable: true # Default(true) will load mathjax/katex script on demand # That is it only render those page who has 'mathjax: true' in Front Matter. # If you set it to false, it will load mathjax/katex srcipt EVERY PAGE. per_page: true engine: mathjax #engine: katex 还需要在文章的Front-matter里打开mathjax开关，如下：123456---title: index.htmldate: 2018-07-05 12:01:30tags:mathjax: true-- 之所以要在文章头里设置开关，是因为考虑只有在用到公式的页面才加载 Mathjax，这样不需要渲染数学公式的页面的访问速度就不会受到影响了。]]></content>
      <categories>
        <category>博客技术</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>machjax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习主要术语]]></title>
    <url>%2F2018%2F07%2Fml-terminology%2F</url>
    <content type="text"><![CDATA[什么是（监督式）机器学习？简单来说，它的定义如下： 机器学习系统通过学习如何组合输入信息来对从未见过的数据做出有用的预测。 下面来了解一下机器学习的基本术语。 标签标签是我们要预测的事物，即简单线性回归中的 y 变量。标签可以是小麦未来的价格、图片中显示的动物品种、音频剪辑的含义或任何事物。 特征 特征是输入变量，即简单线性回归中的 x 变量。简单的机器学习项目可能会使用单个特征，而比较复杂的机器学习项目可能会使用数百万个特征，按如下方式指定： \{x_1, x_2, ... x_N\}在垃圾邮件检测器示例中，特征可能包括： 电子邮件文本中的字词 发件人的地址 发送电子邮件的时段 电子邮件中包含“一种奇怪的把戏”这样的短语。 样本样本是指数据的特定实例：x。（我们采用粗体 x 表示它是一个矢量。）我们将样本分为以下两类： 有标签样本 无标签样本 有标签文件同时包含特征和标签。即： labeled examples: {features, label}: (x, y) 我们使用有标签样本来训练模型。在我们的垃圾邮件检测器示例中，有标签样本是用户明确标记为“垃圾邮件”或“非垃圾邮件”的各个电子邮件。 例如，下表显示了从包含加利福尼亚州房价信息的数据集中抽取的 5 个有标签样本： housingMedianAge（特征） totalRooms（特征） totalBedrooms（特征） medianHouseValue（标签） 15 5612 1283 66900 19 7650 1901 80100 17 720 174 85700 14 1501 337 73400 20 1454 326 65500 无标签样本包含特征，但不包含标签。即： unlabeled examples: {features, ?}: (x, ?) 在使用有标签样本训练了我们的模型之后，我们会使用该模型来预测无标签样本的标签。在垃圾邮件检测器示例中，无标签样本是用户尚未添加标签的新电子邮件。 模型模型定义了特征与标签之间的关系。例如，垃圾邮件检测模型可能会将某些特征与“垃圾邮件”紧密联系起来。我们来重点介绍一下模型生命周期的两个阶段： 训练表示创建或学习模型。也就是说，您向模型展示有标签样本，让模型逐渐学习特征与标签之间的关系。 推断表示将训练后的模型应用于无标签样本。也就是说，您使用训练后的模型来做出有用的预测 (y&#39;)。例如，在推断期间，您可以针对新的无标签样本预测 medianHouseValue。 回归与分类回归模型可预测连续值。例如，回归模型做出的预测可回答如下问题： 加利福尼亚州一栋房产的价值是多少？ 用户点击此广告的概率是多少？ 分类模型可预测离散值。例如，分类模型做出的预测可回答如下问题： 某个指定电子邮件是垃圾邮件还是非垃圾邮件？ 这是一张狗、猫还是仓鼠图片？ 检测监督式学习假设您想开发一种监督式机器学习模型来预测指定的电子邮件是“垃圾邮件”还是“非垃圾邮件”。以下哪些表述正确？ 有些标签可能不可靠。 √ 我们将使用无标签样本来训练模型。 × 主题标头中的字词适合做标签。 × 未标记为“垃圾邮件”或“非垃圾邮件”的电子邮件是无标签样本。√ 注解： 当然。此数据集的标签可能来自将特定电子邮件标记为垃圾邮件的电子邮件用户。由于很少的用户会将每一封可疑的电子邮件都标记为垃圾邮件，因此我们可能很难知道某封电子邮件是否是垃圾邮件。此外，有些垃圾内容发布者或僵尸网络可能会故意提供错误标签来误导我们的模型。 我们将使用有标签样本来训练模型。然后，我们可以对无标签样本运行训练后的模型，以推理无标签的电子邮件是垃圾邮件还是非垃圾邮件。 主题标头中的字词可能是优质特征，但不适合做标签。 由于我们的标签由“垃圾邮件”和“非垃圾邮件”这两个值组成，因此任何尚未标记为垃圾邮件或非垃圾邮件的电子邮件都是无标签样本。 特征和标签假设一家在线鞋店希望创建一种监督式机器学习模型，以便为用户提供合乎个人需求的鞋子推荐。也就是说，该模型会向小马推荐某些鞋子，而向小美推荐另外一些鞋子。以下哪些表述正确？ 鞋的美观程度是一项实用特征。× 鞋码是一项实用特征。√ 用户喜欢的鞋子是一种实用标签。× 用户点击鞋子描述的次数是一项实用特征。√ 注解： 合适的特征应该是具体且可量化的。美观程度是一种过于模糊的概念，不能作为实用特征。美观程度可能是某些具体特征（例如样式和颜色）的综合表现。样式和颜色都比美观程度更适合用作特征。 鞋码是一种可量化的标志，可能对用户是否喜欢推荐的鞋子有很大影响。例如，如果小马穿 43 码的鞋，则该模型不应该推荐 39 码的鞋。 喜好不是可观察且可量化的指标。我们能做到最好的就是针对用户的喜好来搜索可观察的代理指标。 用户可能只是想要详细了解他们喜欢的鞋子。因此，用户点击次数是可观察且可量化的指标，可用来训练合适的标签。正确答案共有 2 个，您目前选中了 2 个。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04 安装 TensorRT]]></title>
    <url>%2F2018%2F06%2Fubuntu-install-tensorrt%2F</url>
    <content type="text"><![CDATA[安装步骤首先下载tar版本的安装包，下载地址需要登陆NVIDIA。安装TensorRT前需要安装Cuda和cudnn，安装步骤可以参考 ubuntu安装cuda和cudnn。打开下载的TensorRT所在路径，解压下载的tar文件：1tar -xzvf TensorRT-XXX.tar.gz 解压好添加环境变量：1234567vim ~/.bashrc # 打开环境变量文件# 将下面三个环境变量写入环境变量文件并保存export LD_LIBRARY_PATH=TensorRT解压路径/lib:$LD_LIBRARY_PATHexport CUDA_INSTALL_DIR=/usr/local/cuda-9.0export CUDNN_INSTALL_DIR=/usr/local/cuda-9.0# 使刚刚修改的环境变量文件生效source ~/.bashrc 下面是安装Python的TensorRT包：进到解压的TensorRT目录下的Python目录：1234# 对于python2sudo pip2 install tensorrt-XXX-cp27-cp27mu-linux_x86_64.whl# 对于python3sudo pip3 install tensorrt-XXX-cp35-cp35m-linux_x86_64.whl 如安装失败请参考文章末尾的解决方案。测试TensorRT是否安装成功：1which tensorrt 会输出TensorRT的安装路径。然后转到uff目录下安装uff包：1234# 对于python2sudo pip2 install uff-0.1.0rc0-py2.py3-none-any.whl# 对于python3sudo pip3 install uff-0.1.0rc0-py2.py3-none-any.whl 测试：1which convert-to-uff 会输出uff的安装路径。拷贝lenet5.uff到python相关目录进行验证：123456sudo cp TensorRT-XXX/data/mnist/lenet5.uff TensorRT-XXX/python/data/mnist/lenet5.uffcd TensorRT-XXX/samples/sampleMNISTmake cleanmakecd /TensorRT-XXX/bin（转到bin目录下面，make后的可执行文件在此目录下）./sample_mnist 命令执行顺利即安装成功。 错误在安装Python的TensorRT包时可能出现的错误：1234In file included from src/cpp/cuda.cpp:1:0: src/cpp/cuda.hpp:14:18: fatal error: cuda.h: No such file or directory compilation terminated. error: command 'x86_64-linux-gnu-gcc' failed with exit status 1 原因显示是找不到cuda.h，根据网上分析是因为用了sudo之后环境变量用的是root的环境变量。参考 解决方案将cuda的安装路径添加到root的环境变量中，在root角色下安装Python的TensorRT包12345vim /etc/profile.d/cuda.sh添加：export PATH=/usr/local/cuda-9.0/bin:$PATHsudo su -pip2 install tensorrt-XXX-cp27-cp27mu-linux_x86_64.whl exit 参考：https://blog.csdn.net/xll_bit/article/details/78376320]]></content>
      <categories>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>cuda</tag>
        <tag>cudnn</tag>
        <tag>tensorrt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 系统查询 cuda 和 cudnn 版本号]]></title>
    <url>%2F2018%2F06%2Fubuntu-inquire-cuda-and-cudnn-version%2F</url>
    <content type="text"><![CDATA[查询 cuda 版本号命令行输入：1cat /usr/local/cuda/version.txt 会输出如下信息：1CUDA Version 8.0.61 显示cuda版本号为：8.0.61 查询 cudnn 版本号命令行输入：1cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2 会输出如下信息：123456#define CUDNN_MAJOR 7#define CUDNN_MINOR 0#define CUDNN_PATCHLEVEL 1--#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)#include "driver_types.h" 显示cudnn版本号为：7.0.1]]></content>
      <categories>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>cuda</tag>
        <tag>cudnn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04 安装 Caffe]]></title>
    <url>%2F2018%2F06%2Fubuntu-install-caffe%2F</url>
    <content type="text"><![CDATA[安装步骤首先安装各种依赖包：12sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev python-dev libgflags-dev libatlas-base-dev libhdf5-serial-dev protobuf-compilersudo apt-get install --no-install-recommends libboost-all-dev 从github上面拷贝下来caffe项目：12git clone https://github.com/BVLC/caffe.gitcd caffe 安装caffe版的SSD拷贝步骤为：123git clone https://github.com/weiliu89/caffe.gitcd caffegit checkout ssd 然后将caffe主目录下面的Makefile.config.example拷贝更名为Makefile.config，打开操作：12cp Makefile.config.example Makefile.configgedit Makefile.config 将其中的：1234#USE_CUDNN := 1#WITH_PYTHON_LAYER := 1INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/includeLIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib 分别更改为：1234USE_CUDNN := 1WITH_PYTHON_LAYER := 1INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serialLIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial 打开 Makefile文件：1gedit Makefile 将其中的：1NVCCFLAGS += -ccbin=$(CXX) -Xcompiler-fPIC $(COMMON_FLAGS) 更改为：1NVCCFLAGS += -D_FORCE_INLINES -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS) 打开/usr/local/cuda/include/crt/host_config.h文件：1sudo gedit /usr/local/cuda/include/crt/host_config.h 将其中的：1#error-- unsupported GNU version! gcc versions later than 4.9 are not supported! 更改为：1//#error-- unsupported GNU version! gcc versions later than 4.9 are not supported! 下面就是编译caffe并测试：123make clean -j8make all -j8 make runtest -j8 最后输出PASS说明测试成功。配置环境变量：1vim ~/.bashrc 在文件末尾写入caffe-pathon的安装路径：1export PYTHONPATH=caffe安装路径/caffe/python:$PYTHONPATH 上述语句中的~表示caffe所在的根目录。是环境变量生效：1source ~/.bashrc 然后执行：1make pycaffe 常见问题CUDA9错误12345NVCC src/caffe/layers/bnll_layer.cunvcc fatal : Unsupported gpu architecture 'compute_20'Makefile:594: recipe for target '.build_release/cuda/src/caffe/layers/bnll_layer.o' failedmake: *** [.build_release/cuda/src/caffe/layers/bnll_layer.o] Error 1make: *** Waiting for unfinished jobs.... 解决方案cuda9不支持‘ compute-20 ’，需要修改Makefile.config文件中CUDA_ARCH设置，将12345678910111213# CUDA architecture setting: going with all of them.# For CUDA &lt; 6.0, comment the *_50 through *_61 lines for compatibility.# For CUDA &lt; 8.0, comment the *_60 and *_61 lines for compatibility.# For CUDA &gt;= 9.0, comment the *_20 and *_21 lines for compatibility.CUDA_ARCH := -gencode arch=compute_20,code=sm_20 \ -gencode arch=compute_20,code=sm_21 \ -gencode arch=compute_30,code=sm_30 \ -gencode arch=compute_35,code=sm_35 \ -gencode arch=compute_50,code=sm_50 \ -gencode arch=compute_52,code=sm_52 \ -gencode arch=compute_60,code=sm_60 \ -gencode arch=compute_61,code=sm_61 \ -gencode arch=compute_61,code=compute_61 中的12-gencode arch=compute_20,code=sm_20 \-gencode arch=compute_20,code=sm_21 \ 删除即可重新编译。 HDF5错误1234src/caffe/net.cpp:8:18: fatal error: hdf5.h: No such file or directorycompilation terminated.Makefile:581: recipe for target '.build_release/src/caffe/net.o' failedmake: *** [.build_release/src/caffe/net.o] Error 1 或者1234567AR -o .build_release/lib/libcaffe.aLD -o .build_release/lib/libcaffe.so.1.0.0/usr/bin/ld: cannot find -lhdf5_hl/usr/bin/ld: cannot find -lhdf5collect2: error: ld returned 1 exit statusMakefile:572: recipe for target '.build_release/lib/libcaffe.so.1.0.0' failedmake: *** [.build_release/lib/libcaffe.so.1.0.0] Error 1 解决方案执行命令安装libhdf5-dev1sudo apt-get install libhdf5-dev 然后再重新编译。 gflags错误12345In file included from src/caffe/net.cpp:10:0:./include/caffe/common.hpp:5:27: fatal error: gflags/gflags.h: No such file or directorycompilation terminated.Makefile:581: recipe for target '.build_release/src/caffe/net.o' failedmake: *** [.build_release/src/caffe/net.o] Error 1 解决方案执行命令安装gflags1sudo apt-get install libgflags-dev 然后再重新编译。 glog错误12345In file included from src/caffe/net.cpp:10:0:./include/caffe/common.hpp:6:26: fatal error: glog/logging.h: No such file or directorycompilation terminated.Makefile:581: recipe for target '.build_release/src/caffe/net.o' failedmake: *** [.build_release/src/caffe/net.o] Error 1 解决方案执行命令安装glog1sudo apt-get install libgoogle-glog-dev 然后再重新编译。 LMDB错误12345In file included from src/caffe/util/db.cpp:3:0:./include/caffe/util/db_lmdb.hpp:8:18: fatal error: lmdb.h: No such file or directorycompilation terminated.Makefile:581: recipe for target '.build_release/src/caffe/util/db.o' failedmake: *** [.build_release/src/caffe/util/db.o] Error 1 解决方案执行命令安装lmdb1sudo apt-get install liblmdb-dev 然后再重新编译。 opencv_imgcodecs opencv_videoio错误12345/usr/bin/ld: cannot find -lopencv_imgcodecs/usr/bin/ld: cannot find -lopencv_videoiocollect2: error: ld returned 1 exit statusMakefile:579: recipe for target '.build_release/lib/libcaffe.so.1.0.0-rc5' failedmake: *** [.build_release/lib/libcaffe.so.1.0.0-rc5] Error 1 解决方案打开Makefile文件，在164行（我的文件）加上opencv_imgcodecs，如下：123LIBRARIES += glog gflags protobuf leveldb snappy \ lmdb boost_system hdf5_hl hdf5 m \ opencv_core opencv_highgui opencv_imgproc opencv_imgcodecs 然后再重新编译。 numpy路径错误1234python/caffe/_caffe.cpp:10:31: fatal error: numpy/arrayobject.h: No such file ordirectorycompilation terminated.make: *** [python/caffe/_caffe.so] Error 1` 解决方案打开python编辑器，通过命令得到numpy的安装路径：123import numpydirs = numpy.get_include()print(dirs) 然后就能看到numpy的安装路径，打开caffe目录下的Makefile.config文件，将65行（我的文件）的路径：/usr/lib/python2.7/dist-packages/numpy/core/include换成刚刚得到numpy的安装路径，然后重新编译。]]></content>
      <categories>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>caffe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04 安装 cuda9 和 cudnn7]]></title>
    <url>%2F2018%2F06%2Fubuntu-install-cuda-and-cudnn%2F</url>
    <content type="text"><![CDATA[安装步骤安装 cuda首先下载 cuda9.0 下载地址的 (runfile) 安装文件，下载完成进到文件下载的目录下，给安装文件赋予权限：1sudo chmod 777 XXX.run # XXX为安装文件的文件名 执行安装文件：1sudo sh XXX.run 在看完协议选择 Install NVIDIA Accelerated Graphics Driver for nvidia 时，选择 no，其他的可全部选择 yes 和默认回车；并且在查看协议时有快捷键 Ctrl+D 进行翻页。下面安装完成配置环境变量：打开环境变量文件1gedit ~/.bashrc 在文件末尾加上安装的 cuda9.0 路径12export PATH=/usr/local/cuda-9.0/bin:$PATHexport LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64:$LD_LIBRARY_PATH 配置完环境变量，使其生效：1source ~/.bashrc 然后进行测试：123cd /usr/local/cuda-9.0/samples/1_Utilities/deviceQuerysudo makesudo ./deviceQuery 测试结果有输出PASS，即为正确安装。 安装 cudnn首先下载 cudnn7 下载路径（下载 cudnn7 需要登陆 NVIDIA ，没有 NVIDIA 账号的注册一个就行了。）下载 tgz 压缩文件。首先解压 tgz 压缩文件：1tar -xzvf cudnn-XXX.tgz 接着复制文件到 cuda 路径下：123sudo cp cuda/include/cudnn.h /usr/local/cuda/includesudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn* 复制完成然后使用命令，可以看到输出相应的 cuda 和 cudnn 的版本信息1nvcc -V 如果提示库缺失错误，可参考以下命令：1234sudo cp /usr/local/cuda-9.0/lib64/libcudart.so.9.0 /usr/local/lib/libcudart.so.9.0 &amp;&amp; sudo ldconfigsudo cp /usr/local/cuda-9.0/lib64/libcublas.so.9.0 /usr/local/lib/libcublas.so.9.0 &amp;&amp; sudo ldconfigsudo cp /usr/local/cuda-9.0/lib64/libcurand.so.9.0 /usr/local/lib/libcurabd.so.9.0 &amp;&amp; sudo ldconfigsudo cp /usr/local/cuda-9.0/lib64/libcudnn.so.7 /usr/local/lib/libcudnn.so.7 &amp;&amp; sudo ldconfig]]></content>
      <categories>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>cuda</tag>
        <tag>cudnn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04 安装 NVIDIA 驱动]]></title>
    <url>%2F2018%2F06%2Fubuntu-install-nvidia-drive%2F</url>
    <content type="text"><![CDATA[问题描述 在安装了NVIDIA驱动后出现了进入Ubuntu循环登录的问题。 解决方案1.进入命令行界面Ctrl+Alt+F1打开编辑配置文件：1vim /etc/modprobe.d/blacklist.conf 在最后一行添加：1blacklist nouveau 2.禁用 nouveau 第三方驱动，之后也不需要改回来执行：12sudo update-initramfs -ulsmod | grep nouveau 没有输出即屏蔽好了。 3.禁用X服务，执行：1sudo /etc/init.d/lightdm stop 4.给驱动run文件赋予执行权限1sudo chmod a+x NVIDIA***.run 安装(注意 参数)1sudo ./NVIDIA***.run –no-opengl-files 5.如果还无法进入桌面，这是因为驱动修改了xorg的配置，可执行一下命令：12cd /usr/share/X11/xorg.conf.d/ sudo mv nvidia-drm-outputclass.conf nvidia-drm-outputclass.conf.bak 参考http://blog.csdn.net/u012759136/article/details/53355781]]></content>
      <categories>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>nvidia驱动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04 安装 OpenCV2.4.13.6]]></title>
    <url>%2F2018%2F06%2Fubuntu-install-opencv%2F</url>
    <content type="text"><![CDATA[安装步骤1.通过命令安装各种软件包123sudo apt-get install build-essentialsudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-devsudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev 2.进到安装路径下拷贝 OpenCV 源码1git clone https://github.com/opencv/opencv.git 3.选择安装的 OpenCV 版本号12cd opencvgit checkout -b 2.4.13.7 4.使用 Cmake 编译 OpenCV 源码123mkdir releasecd releasecmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local .. 5.make 安装 OpenCV12make -j4sudo make install 安装到此结束。 测试命令进入 Python 编辑器12import cv2print(cv2.__version__) 会输出 OpenCV 的版本号。 cuda 9.0 与 opencv 版本匹配问题：Cmake 过程中会出现以下问题： 错误123CMake Error: The following variables are used in this project, but they are set to NOTFOUND.Please set them or make sure they are set and tested correctly in the CMake files:CUDA_nppi_LIBRARY (ADVANCED) 原因在cuda9里面，NVIDIA把 libnppi.so换成libnppc.so libnppial.so libnppicc.so libnppicom.so libnppidei.so libnppif.so libnppig.so libnppim.so libnppist.so libnppisu.so libnppitc.so libnpps.so 解决方案修改opencv/cmake/FindCUDA.cmake 文件，将其中的1unset(CUDA_nppi_LIBRARY CACHE) 替换为：12345678910unset(CUDA_nppial_LIBRARY CACHE)unset(CUDA_nppicc_LIBRARY CACHE)unset(CUDA_nppicom_LIBRARY CACHE)unset(CUDA_nppidei_LIBRARY CACHE)unset(CUDA_nppif_LIBRARY CACHE)unset(CUDA_nppig_LIBRARY CACHE)unset(CUDA_nppim_LIBRARY CACHE)unset(CUDA_nppist_LIBRARY CACHE)unset(CUDA_nppisu_LIBRARY CACHE)unset(CUDA_nppitc_LIBRARY CACHE) 将12find_cuda_helper_libs(nppi)set(CUDA_npp_LIBRARY"$&#123;CUDA_nppc_LIBRARY&#125;;$&#123;CUDA_nppi_LIBRARY&#125;;$&#123;CUDA_npps_LIBRARY&#125;") 替换为1234567891011find_cuda_helper_libs(nppial)find_cuda_helper_libs(nppicc)find_cuda_helper_libs(nppicom)find_cuda_helper_libs(nppidei)find_cuda_helper_libs(nppif)find_cuda_helper_libs(nppig)find_cuda_helper_libs(nppim)find_cuda_helper_libs(nppist)find_cuda_helper_libs(nppisu)find_cuda_helper_libs(nppitc)set(CUDA_npp_LIBRARY "$&#123;CUDA_nppc_LIBRARY&#125;;$&#123;CUDA_nppial_LIBRARY&#125;;$&#123;CUDA_nppicc_LIBRARY&#125;;$&#123;CUDA_nppicom_LIBRARY&#125;;$&#123;CUDA_nppidei_LIBRARY&#125;;$&#123;CUDA_nppif_LIBRARY&#125;;$&#123;CUDA_nppig_LIBRARY&#125;;$&#123;CUDA_nppim_LIBRARY&#125;;$&#123;CUDA_nppist_LIBRARY&#125;;$&#123;CUDA_nppisu_LIBRARY&#125;;$&#123;CUDA_nppitc_LIBRARY&#125;;$&#123;CUDA_npps_LIBRARY&#125;") 错误1opencv nvcc fatal : Unsupported gpu architecture 'compute_20' 原因cuda9不支持‘ compute-20 ’ 解决方案：更改 OpenCVDetectCUDA.cmake 文件，把有关 ‘ compute-20 ’ 的全删掉将1234567if(CUDA_GENERATION STREQUAL "Fermi") set(__cuda_arch_bin "3.0 3.5") elseif(CUDA_GENERATION STREQUAL "Kepler") if($&#123;CUDA_VERSION&#125; VERSION_LESS "5.0") set(__cuda_arch_bin "2.0 2.1") else() set(__cuda_arch_bin "3.0 3.5") 替换为1234567if(CUDA_GENERATION STREQUAL "Fermi") set(__cuda_arch_bin "3.0 3.5") elseif(CUDA_GENERATION STREQUAL "Kepler") if($&#123;CUDA_VERSION&#125; VERSION_LESS "5.0") set(__cuda_arch_bin "3.0") else() set(__cuda_arch_bin "3.0 3.5") 将：1234if($&#123;CUDA_VERSION&#125; VERSION_LESS "5.0") set(__cuda_arch_bin "1.1 1.2 1.3 2.0 2.1(2.0) 3.0")elseif($&#123;CUDA_VERSION&#125; VERSION_GREATER "6.5") set(__cuda_arch_bin "2.0 2.1(2.0) 3.0 3.5") 替换为：1234if($&#123;CUDA_VERSION&#125; VERSION_LESS "5.0") set(__cuda_arch_bin "1.1 1.2 1.3 2.0 2.1(2.0) 3.0")elseif($&#123;CUDA_VERSION&#125; VERSION_GREATER "6.5") set(__cuda_arch_bin "3.0 3.5") 然后 cmake 成功。 参考https://docs.opencv.org/2.4/doc/tutorials/introduction/linux_install/linux_install.html https://stackoverflow.com/questions/46584000/cmake-error-variables-are-set-to-notfound]]></content>
      <categories>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>cuda</tag>
        <tag>OpenCV</tag>
      </tags>
  </entry>
</search>
